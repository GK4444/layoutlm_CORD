{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bertlarge.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNZ2iuFZMT7HAnQVPmtyrWw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"24opowDSuiP0","executionInfo":{"status":"ok","timestamp":1606485693126,"user_tz":-60,"elapsed":2,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["!pip install transformers\n","!pip install seqeval"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNFjqj90Hp7N","executionInfo":{"status":"ok","timestamp":1606485701361,"user_tz":-60,"elapsed":861,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"65484462-5a19-4c16-9497-c07ee7a58037"},"source":["import numpy as np\n","import pickle\n","import random\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","#### METRICS ####\n","from seqeval.metrics import (\n","    classification_report,\n","    f1_score,\n","    precision_score,\n","    recall_score)\n","\n","\n","##### UTILS ######\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm, trange\n","from torch import nn\n","from torch.nn import CrossEntropyLoss, MSELoss\n","from transformers import BertConfig, BertModel, BertPreTrainedModel, get_linear_schedule_with_warmup, AdamW, BertTokenizerFast, BertForTokenClassification\n","from torch.nn import LayerNorm as BertLayerNorm"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9vtQBkYPwe5B"},"source":["Load the data"]},{"cell_type":"code","metadata":{"id":"8C1po-tlH75q","executionInfo":{"status":"ok","timestamp":1606485702618,"user_tz":-60,"elapsed":546,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["## Import Data\n","path = '/content/drive/My Drive/layoutlm/'\n","train = pickle.load(open(path + 'train.pkl', 'rb'))\n","val = pickle.load(open(path + 'val.pkl', 'rb'))\n","test = pickle.load(open(path + 'test.pkl', 'rb'))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sEo2CZ3mwS84"},"source":["This is simply a code to see if there are some negative bounding boxes (I find some, they were close to zero, then I set them to zero)"]},{"cell_type":"code","metadata":{"id":"eKM5ubNfhUEs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606485704224,"user_tz":-60,"elapsed":527,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"257d1516-420e-44e2-8d8d-091ae5651647"},"source":["for index, elem in enumerate(train[2]):\n","  for i,e in enumerate(elem):\n","    if not all(np.array(e) >= 0):\n","      print(e)\n","      print(index, i)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[-4, 426, 213, 396]\n","669 0\n","[-3, 466, 112, 435]\n","669 3\n","[-1, 529, 223, 508]\n","669 6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zf7Tl8-ZjDIr","executionInfo":{"status":"ok","timestamp":1606485705787,"user_tz":-60,"elapsed":471,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["train[2][669][0] = [0, 426, 213, 396]\n","train[2][669][3] = [0, 466, 112, 435]\n","train[2][669][6] = [0, 529, 223, 508]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"VThQLP2Tiu_-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606485706643,"user_tz":-60,"elapsed":593,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"1a602a0f-3e92-4215-9d5d-5537a4db1e59"},"source":["for index, elem in enumerate(test[2]):\n","  for i,e in enumerate(elem):\n","    if not all(np.array(e) >= 0):\n","      print(e)\n","      print(index, i)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[-3, 891, 106, 862]\n","88 17\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RWTTF_GajZz2","executionInfo":{"status":"ok","timestamp":1606485708046,"user_tz":-60,"elapsed":628,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["test[2][88][17] = [0, 891, 106, 862]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DnAtbMfw8oaW"},"source":["# Labels Analysis"]},{"cell_type":"code","metadata":{"id":"eMNyf22lvUqR","executionInfo":{"status":"ok","timestamp":1606485709341,"user_tz":-60,"elapsed":575,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["all_labels = [item for sublist in train[1] for item in sublist] + [item for sublist in val[1] for item in sublist] + [item for sublist in test[1] for item in sublist]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fg8kIOrFv0F3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606485709932,"user_tz":-60,"elapsed":558,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"165b9c82-923d-4a6a-fd25-2753ff6ec046"},"source":["from collections import Counter\n","Counter(all_labels)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'menu.cnt': 2429,\n","         'menu.discountprice': 403,\n","         'menu.etc': 19,\n","         'menu.itemsubtotal': 7,\n","         'menu.nm': 6599,\n","         'menu.num': 109,\n","         'menu.price': 2585,\n","         'menu.sub_cnt': 189,\n","         'menu.sub_etc': 10,\n","         'menu.sub_nm': 822,\n","         'menu.sub_price': 160,\n","         'menu.sub_unitprice': 14,\n","         'menu.unitprice': 750,\n","         'menu.vatyn': 9,\n","         'sub_total.discount_price': 191,\n","         'sub_total.etc': 283,\n","         'sub_total.othersvc_price': 6,\n","         'sub_total.service_price': 353,\n","         'sub_total.subtotal_price': 1483,\n","         'sub_total.tax_price': 1283,\n","         'total.cashprice': 1397,\n","         'total.changeprice': 1299,\n","         'total.creditcardprice': 411,\n","         'total.emoneyprice': 129,\n","         'total.menuqty_cnt': 630,\n","         'total.menutype_cnt': 130,\n","         'total.total_etc': 89,\n","         'total.total_price': 2120,\n","         'void_menu.nm': 3,\n","         'void_menu.price': 1})"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"ZlGPB3IPwjB_"},"source":["As we can see there are some labels that contains few examples, I decided to replace them by the \"neutral\" label \"O\""]},{"cell_type":"code","metadata":{"id":"_ic2qLS88x8P","executionInfo":{"status":"ok","timestamp":1606485712444,"user_tz":-60,"elapsed":1293,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["replacing_labels = {'menu.etc': 'O', 'mneu.itemsubtotal': 'O', 'menu.sub_etc': 'O', 'menu.sub_unitprice': 'O', 'menu.vatyn': 'O',\n","                  'void_menu.nm': 'O', 'void_menu.price': 'O', 'sub_total.othersvc_price': 'O'}"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"3c3XitV9AN8W","executionInfo":{"status":"ok","timestamp":1606485714040,"user_tz":-60,"elapsed":666,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["def replace_elem(elem):\n","  try:\n","    return replacing_labels[elem]\n","  except KeyError:\n","    return elem\n","def replace_list(ls):\n","  return [replace_elem(elem) for elem in ls]\n","train[1] = [replace_list(ls) for ls in train[1]]\n","val[1] = [replace_list(ls) for ls in val[1]]\n","test[1] = [replace_list(ls) for ls in test[1]]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCjWSztSBG7-","executionInfo":{"status":"ok","timestamp":1606485714745,"user_tz":-60,"elapsed":482,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"9864dcf2-5d63-4757-bb21-25af53bf4391"},"source":["all_labels = [item for sublist in train[1] for item in sublist] + [item for sublist in val[1] for item in sublist] + [item for sublist in test[1] for item in sublist]\n","Counter(all_labels)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'O': 62,\n","         'menu.cnt': 2429,\n","         'menu.discountprice': 403,\n","         'menu.itemsubtotal': 7,\n","         'menu.nm': 6599,\n","         'menu.num': 109,\n","         'menu.price': 2585,\n","         'menu.sub_cnt': 189,\n","         'menu.sub_nm': 822,\n","         'menu.sub_price': 160,\n","         'menu.unitprice': 750,\n","         'sub_total.discount_price': 191,\n","         'sub_total.etc': 283,\n","         'sub_total.service_price': 353,\n","         'sub_total.subtotal_price': 1483,\n","         'sub_total.tax_price': 1283,\n","         'total.cashprice': 1397,\n","         'total.changeprice': 1299,\n","         'total.creditcardprice': 411,\n","         'total.emoneyprice': 129,\n","         'total.menuqty_cnt': 630,\n","         'total.menutype_cnt': 130,\n","         'total.total_etc': 89,\n","         'total.total_price': 2120})"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"gJ_8wwhWwvUY"},"source":["Now we have to save all the unique labels in a list. (mandatory for the tokenclassification)"]},{"cell_type":"code","metadata":{"id":"sU67bqUsBM65","executionInfo":{"status":"ok","timestamp":1606485717200,"user_tz":-60,"elapsed":499,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["labels = list(set(all_labels))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxlPHOdsyar7"},"source":["# Some aux functions"]},{"cell_type":"code","metadata":{"id":"r5uOfQyIXTOA","executionInfo":{"status":"ok","timestamp":1606485741424,"user_tz":-60,"elapsed":498,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["def set_seed(seed): ## for reproductibility\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9msa1C8RytLs"},"source":["This is for making the structure of our data match the one needed by the model (mandatory)"]},{"cell_type":"code","metadata":{"id":"ipRLhsY1yo-I","executionInfo":{"status":"ok","timestamp":1606485743466,"user_tz":-60,"elapsed":1225,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["class CordDataset(Dataset):\n","    def __init__(self, examples, tokenizer, labels, pad_token_label_id):\n","        features = convert_examples_to_features(\n","            examples,\n","            labels,\n","            max_seq_length,\n","            tokenizer,\n","            cls_token_at_end=False,\n","            # xlnet has a cls token at the end\n","            cls_token=tokenizer.cls_token,\n","            cls_token_segment_id=0,\n","            sep_token=tokenizer.sep_token,\n","            sep_token_extra=False,\n","            # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n","            pad_on_left=False,\n","            # pad on the left for xlnet\n","            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n","            pad_token_segment_id=0,\n","            pad_token_label_id=pad_token_label_id,\n","        )\n","\n","        self.features = features\n","        # Convert to Tensors and build dataset\n","        self.all_input_ids = torch.tensor(\n","            [f.input_ids for f in features], dtype=torch.long\n","        )\n","        self.all_input_mask = torch.tensor(\n","            [f.input_mask for f in features], dtype=torch.long\n","        )\n","        self.all_segment_ids = torch.tensor(\n","            [f.segment_ids for f in features], dtype=torch.long\n","        )\n","        self.all_label_ids = torch.tensor(\n","            [f.label_ids for f in features], dtype=torch.long\n","        )\n","        self.all_bboxes = torch.tensor([f.boxes for f in features], dtype=torch.long)\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, index):\n","        return (\n","            self.all_input_ids[index],\n","            self.all_input_mask[index],\n","            self.all_segment_ids[index],\n","            self.all_label_ids[index],\n","            self.all_bboxes[index],\n","        )\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(\n","        self,\n","        input_ids,\n","        input_mask,\n","        segment_ids,\n","        label_ids,\n","        boxes\n","    ):\n","        assert (\n","            0 <= all(boxes) <= 1000\n","        ), \"Error with input bbox ({}): the coordinate value is not between 0 and 1000\".format(\n","            boxes\n","        )\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_ids = label_ids\n","        self.boxes = boxes\n","\n","def convert_examples_to_features(\n","    examples,\n","    label_list,\n","    max_seq_length,\n","    tokenizer,\n","    cls_token_at_end=False,\n","    cls_token=\"[CLS]\",\n","    cls_token_segment_id=1,\n","    sep_token=\"[SEP]\",\n","    sep_token_extra=False,\n","    pad_on_left=False,\n","    pad_token=0,\n","    cls_token_box=[0, 0, 0, 0],\n","    sep_token_box=[1000, 1000, 1000, 1000],\n","    pad_token_box=[0, 0, 0, 0],\n","    pad_token_segment_id=0,\n","    pad_token_label_id=-1,\n","    sequence_a_segment_id=0,\n","    mask_padding_with_zero=True,\n","):\n","    \"\"\" Loads a data file into a list of `InputBatch`s\n","        `cls_token_at_end` define the location of the CLS token:\n","            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n","            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n","        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n","    \"\"\"\n","\n","    label_map = {label: i for i, label in enumerate(label_list)}\n","\n","    features = []\n","    for i in range(len(examples[0])):\n","        width, height = 1000, 1000\n","        words = examples[0]\n","        labels = examples[1]\n","        boxes = examples[2]\n","\n","        tokens = []\n","        token_boxes = []\n","        label_ids = []\n","        for word, label, box in zip(\n","            words[i], labels[i], boxes[i]\n","        ):\n","            if len(word) < 1: # SKIP EMPTY WORD\n","              continue\n","            word_tokens = tokenizer.tokenize(word)\n","            tokens.extend(word_tokens)\n","            token_boxes.extend([box] * len(word_tokens))\n","            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n","            label_ids.extend(\n","                [label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n","\n","        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n","        special_tokens_count = 3 if sep_token_extra else 2\n","        if len(tokens) > max_seq_length - special_tokens_count:\n","            tokens = tokens[: (max_seq_length - special_tokens_count)]\n","            token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n","            label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n","\n","        # The convention in BERT is:\n","        # (a) For sequence pairs:\n","        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n","        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n","        # (b) For single sequences:\n","        #  tokens:   [CLS] the dog is hairy . [SEP]\n","        #  type_ids:   0   0   0   0  0     0   0\n","        #\n","        # Where \"type_ids\" are used to indicate whether this is the first\n","        # sequence or the second sequence. The embedding vectors for `type=0` and\n","        # `type=1` were learned during pre-training and are added to the wordpiece\n","        # embedding vector (and position vector). This is not *strictly* necessary\n","        # since the [SEP] token unambiguously separates the sequences, but it makes\n","        # it easier for the model to learn the concept of sequences.\n","        #\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\n","        # used as as the \"sentence vector\". Note that this only makes sense because\n","        # the entire model is fine-tuned.\n","        tokens += [sep_token]\n","        token_boxes += [sep_token_box]\n","        label_ids += [pad_token_label_id]\n","        if sep_token_extra:\n","            # roberta uses an extra separator b/w pairs of sentences\n","            tokens += [sep_token]\n","            token_boxes += [sep_token_box]\n","            label_ids += [pad_token_label_id]\n","        segment_ids = [sequence_a_segment_id] * len(tokens)\n","\n","        if cls_token_at_end:\n","            tokens += [cls_token]\n","            token_boxes += [cls_token_box]\n","            label_ids += [pad_token_label_id]\n","            segment_ids += [cls_token_segment_id]\n","        else:\n","            tokens = [cls_token] + tokens\n","            token_boxes = [cls_token_box] + token_boxes\n","            label_ids = [pad_token_label_id] + label_ids\n","            segment_ids = [cls_token_segment_id] + segment_ids\n","\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","        # tokens are attended to.\n","        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n","\n","        # Zero-pad up to the sequence length.\n","        padding_length = max_seq_length - len(input_ids)\n","        if pad_on_left:\n","            input_ids = ([pad_token] * padding_length) + input_ids\n","            input_mask = (\n","                [0 if mask_padding_with_zero else 1] * padding_length\n","            ) + input_mask\n","            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n","            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n","            token_boxes = ([pad_token_box] * padding_length) + token_boxes\n","        else:\n","            input_ids += [pad_token] * padding_length\n","            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n","            segment_ids += [pad_token_segment_id] * padding_length\n","            label_ids += [pad_token_label_id] * padding_length\n","            token_boxes += [pad_token_box] * padding_length\n","\n","        assert len(input_ids) == max_seq_length\n","        assert len(input_mask) == max_seq_length\n","        assert len(segment_ids) == max_seq_length\n","        assert len(label_ids) == max_seq_length\n","        assert len(token_boxes) == max_seq_length\n","\n","        features.append(\n","            InputFeatures(\n","                input_ids=input_ids,\n","                input_mask=input_mask,\n","                segment_ids=segment_ids,\n","                label_ids=label_ids,\n","                boxes=token_boxes,\n","            )\n","        )\n","    return features\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6shAbUJzWeV"},"source":["This function is for the evaluation (loss, f1, precision , recall)"]},{"cell_type":"code","metadata":{"id":"lK-jb-vXzahD","executionInfo":{"status":"ok","timestamp":1606485746651,"user_tz":-60,"elapsed":516,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["def results(preds, out_label_ids, labels, loss_):\n","  preds = np.argmax(preds, axis=2)\n","\n","  label_map = {i: label for i, label in enumerate(labels)}\n","\n","  out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n","  preds_list = [[] for _ in range(out_label_ids.shape[0])]\n","\n","  for i in range(out_label_ids.shape[0]):\n","      for j in range(out_label_ids.shape[1]):\n","          if out_label_ids[i, j] != pad_token_label_id:\n","              out_label_list[i].append(label_map[out_label_ids[i][j]])\n","              preds_list[i].append(label_map[preds[i][j]])\n","\n","  results = {\n","      \"loss\": loss_,\n","      \"precision\": precision_score(out_label_list, preds_list),\n","      \"recall\": recall_score(out_label_list, preds_list),\n","      \"f1\": f1_score(out_label_list, preds_list),\n","  }\n","  return results"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bahaNkwL0Tor"},"source":["# Load models"]},{"cell_type":"code","metadata":{"id":"Po75bopj08eN","executionInfo":{"status":"ok","timestamp":1606485749540,"user_tz":-60,"elapsed":533,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1UBWYX1XyWo"},"source":["model_path = '/content/drive/My Drive/layoutlm/'\n","num_labels = len(labels)\n","config_class, model_class, tokenizer_class = BertConfig, BertForTokenClassification, BertTokenizerFast\n","config = config_class.from_pretrained(model_path, num_labels=num_labels+1)\n","tokenizer = tokenizer_class.from_pretrained('bert-large-uncased', do_lower_case=True)\n","model = model_class.from_pretrained('bert-large-uncased', from_tf=bool(\".ckpt\" in model_path), config=config)\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sf3XgoQS0YXY"},"source":["# Generate our training / validation set"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwSEe05VCGYb","executionInfo":{"status":"ok","timestamp":1606485808294,"user_tz":-60,"elapsed":537,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"291e5b76-c7fd-4f77-ea2b-b51ca9038b36"},"source":["sum_ = []\n","for x in train[0]:\n","  sum_.append(len(x))\n","print(max(sum_))\n","print(min(sum_))\n","print(sum(sum_)/len(sum_))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["135\n","5\n","24.21375\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oO_wnwuiaGYp","executionInfo":{"status":"ok","timestamp":1606485816432,"user_tz":-60,"elapsed":2127,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["max_seq_length = 150\n","pad_token_label_id = CrossEntropyLoss().ignore_index\n","train_dataset = CordDataset(train, tokenizer, labels, pad_token_label_id)\n","validation_dataset = CordDataset(val, tokenizer, labels, pad_token_label_id)\n","model_type = 'bert'"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnsAw1XcOVi1","executionInfo":{"status":"ok","timestamp":1606485818045,"user_tz":-60,"elapsed":698,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["train_batch_size = 8\n","learning_rate = 1e-4\n","adam_epsilon = 1e-8\n","weight_decay = 0.0\n","num_train_epochs = 4 ## To fine-tune (adding drop out so that It can lead to overfit less)\n","max_steps = 0\n","gradient_accumulation_steps = 1\n","max_grad_norm = 1.0\n","warmup_steps = 0\n","seed = 42\n","\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(\n","        train_dataset,\n","        sampler=train_sampler,\n","        batch_size=train_batch_size,\n","        collate_fn=None,\n","    )\n","valid_sampler = RandomSampler(validation_dataset)\n","valid_dataloader = DataLoader(\n","        validation_dataset,\n","        sampler=valid_sampler,\n","        batch_size=train_batch_size,\n","        collate_fn=None,\n","    )\n","if max_steps > 0:\n","    t_total = max_steps\n","    num_train_epochs = (\n","        args.max_steps\n","        // (len(train_dataloader) // gradient_accumulation_steps)\n","        + 1\n","    )\n","else:\n","    t_total = (\n","        len(train_dataloader)\n","        // gradient_accumulation_steps\n","        * num_train_epochs\n","    )\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","        {\n","            \"params\": [\n","                p\n","                for n, p in model.named_parameters()\n","                if not any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": weight_decay,\n","        },\n","        {\n","            \"params\": [\n","                p\n","                for n, p in model.named_parameters()\n","                if any(nd in n for nd in no_decay)\n","            ],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","optimizer = AdamW(\n","        optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon\n","    )\n","scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=warmup_steps, num_training_steps=t_total\n","    )"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DuXqu7AJ0qhC"},"source":["# TRAIN"]},{"cell_type":"code","metadata":{"id":"5BfPvHDGPErD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606486461663,"user_tz":-60,"elapsed":636268,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"57d4c802-c19e-41d5-b213-1e380478186e"},"source":["global_step = 0\n","model.zero_grad()\n","train_iterator = trange(int(num_train_epochs), desc=\"Epoch\")\n","set_seed(seed)\n","for _ in train_iterator:\n","  #epoch_iterator = tqdm(\n","      #train_dataloader, desc=\"Iteration\")\n","  tr_loss = 0.0\n","  nb_train_steps = 0\n","  preds_train = None\n","  out_label_ids = None\n","  for step, batch in enumerate(train_dataloader):\n","      model.train()\n","      inputs = {\n","          \"input_ids\": batch[0].to(device),\n","          \"attention_mask\": batch[1].to(device),\n","          \"labels\": batch[3].to(device),\n","      }\n","      if model_type in [\"layoutlm\"]:\n","          inputs[\"bbox\"] = batch[4].to(device)\n","      inputs[\"token_type_ids\"] = (\n","          batch[2].to(device) if model_type in [\"bert\", \"layoutlm\"] else None)\n","      outputs = model(**inputs)\n","      # model outputs are always tuple in pytorch-transformers (see doc)\n","      loss, logits = outputs\n","      loss.backward()\n","\n","      tr_loss += loss.item()\n","      #if (step+1) % 25 == 0:\n","        #print(f\"Train Epoch : {step+1}/{len(train_dataloader)}\")\n","\n","      if (step + 1) % gradient_accumulation_steps == 0:\n","          torch.nn.utils.clip_grad_norm_(\n","                  model.parameters(), max_grad_norm\n","              )\n","          optimizer.step()\n","          scheduler.step()  # Update learning rate schedule\n","          model.zero_grad()\n","          global_step += 1\n","      nb_train_steps += 1\n","      if preds_train is None:\n","          preds_train = logits.detach().cpu().numpy()\n","          out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n","      else:\n","          preds_train = np.append(preds_train, logits.detach().cpu().numpy(), axis=0)\n","          out_label_ids = np.append(\n","              out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n","  res = results(preds_train, out_label_ids, labels, tr_loss/len(train_dataloader))\n","  print('Train Results', res)\n","\n","  ###### EVALUATION #######\n","\n","  #epoch_iterator = tqdm(valid_dataloader, desc=\"Iteration\")\n","  eval_loss = 0.0\n","  nb_eval_steps = 0\n","  preds_val = None\n","  out_label_ids = None\n","  model.eval()\n","  for step, batch in enumerate(valid_dataloader):\n","    with torch.no_grad():\n","      inputs = {\n","          \"input_ids\": batch[0].to(device),\n","          \"attention_mask\": batch[1].to(device),\n","          \"labels\": batch[3].to(device),\n","      }\n","      if model_type in [\"layoutlm\"]:\n","          inputs[\"bbox\"] = batch[4].to(device)\n","      inputs[\"token_type_ids\"] = (\n","          batch[2].to(device) if model_type in [\"bert\", \"layoutlm\"] else None)\n","      # model outputs are always tuple in pytorch-transformers (see doc)\n","      outputs = model(**inputs)\n","      tmp_eval_loss, logits = outputs[:2]\n","      eval_loss += tmp_eval_loss.item()\n","    nb_eval_steps += 1\n","    if preds_val is None:\n","      preds_val = logits.detach().cpu().numpy()\n","      out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n","    else:\n","      preds_val = np.append(preds_val, logits.detach().cpu().numpy(), axis=0)\n","      out_label_ids = np.append(\n","          out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0\n","      )\n","  eval_loss = eval_loss / nb_eval_steps\n","  res = results(preds_val, out_label_ids, labels, eval_loss)\n","  print('Validation results',res)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train Results {'loss': 0.7824301970750094, 'precision': 0.6843320017754105, 'recall': 0.7189889945905614, 'f1': 0.7012325465047529}\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  25%|██▌       | 1/4 [02:39<07:58, 159.63s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation results {'loss': 0.25740169705106664, 'precision': 0.893312101910828, 'recall': 0.908502024291498, 'f1': 0.9008430349257326}\n","Train Results {'loss': 0.23918551264330745, 'precision': 0.8841217455078841, 'recall': 0.8994590561462413, 'f1': 0.8917244567730005}\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  50%|█████     | 2/4 [05:18<05:18, 159.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation results {'loss': 0.20990515396428797, 'precision': 0.9218877135882831, 'recall': 0.9174089068825911, 'f1': 0.9196428571428572}\n","Train Results {'loss': 0.1167666693078354, 'precision': 0.9442747384985652, 'recall': 0.9514083193434061, 'f1': 0.9478281068524972}\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  75%|███████▌  | 3/4 [07:57<02:39, 159.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation results {'loss': 0.19350521438396895, 'precision': 0.9245585874799358, 'recall': 0.9327935222672065, 'f1': 0.9286577992744861}\n","Train Results {'loss': 0.060243648015894, 'precision': 0.971986970684039, 'recall': 0.9740720014922589, 'f1': 0.973028369124703}\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 4/4 [10:35<00:00, 158.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation results {'loss': 0.18163511672845253, 'precision': 0.946645109135004, 'recall': 0.9481781376518219, 'f1': 0.9474110032362459}\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"HLdpqOqHnGxW"},"source":["# TEST"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGDPJFgP4pfX","executionInfo":{"status":"ok","timestamp":1606486467122,"user_tz":-60,"elapsed":562,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"dd1a5d4f-b647-4907-8338-5442e2c018b8"},"source":["for index, e in enumerate(test[2]):\n","  for index_,l in enumerate(e):\n","    if l[1] < l[3]:\n","      print(index, index_)\n","      print(l)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["54 15\n","[105, 726, 498, 738]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yhBHNhyV5D40","executionInfo":{"status":"ok","timestamp":1606486468955,"user_tz":-60,"elapsed":636,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["test[2][54][15] = [105, 738, 498, 726]"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgUBgVEM4rHQ","executionInfo":{"status":"ok","timestamp":1606486470086,"user_tz":-60,"elapsed":650,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["test_dataset = CordDataset(test, tokenizer, labels, pad_token_label_id)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xrgr8-F_pu0s","executionInfo":{"status":"ok","timestamp":1606486470806,"user_tz":-60,"elapsed":689,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["def results_test(preds, out_label_ids, labels):\n","  preds = np.argmax(preds, axis=2)\n","\n","  label_map = {i: label for i, label in enumerate(labels)}\n","\n","  out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n","  preds_list = [[] for _ in range(out_label_ids.shape[0])]\n","\n","  for i in range(out_label_ids.shape[0]):\n","      for j in range(out_label_ids.shape[1]):\n","          if out_label_ids[i, j] != pad_token_label_id:\n","              out_label_list[i].append(label_map[out_label_ids[i][j]])\n","              preds_list[i].append(label_map[preds[i][j]])\n","\n","  results = {\n","      \"precision\": precision_score(out_label_list, preds_list),\n","      \"recall\": recall_score(out_label_list, preds_list),\n","      \"f1\": f1_score(out_label_list, preds_list),\n","  }\n","  return results, classification_report(out_label_list, preds_list)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifR-pkUu8a9A","executionInfo":{"status":"ok","timestamp":1606486472691,"user_tz":-60,"elapsed":509,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["val_r, class_r = results_test(preds_val, out_label_ids, labels)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4II6MORDl_o","executionInfo":{"status":"ok","timestamp":1606486486264,"user_tz":-60,"elapsed":713,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"8559c5ed-33a7-402d-bfa0-12006cc43e4a"},"source":["val_r"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'f1': 0.9474110032362459,\n"," 'precision': 0.946645109135004,\n"," 'recall': 0.9481781376518219}"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P83YLa0X9sFs","executionInfo":{"status":"ok","timestamp":1606486474251,"user_tz":-60,"elapsed":659,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"2537d205-b6ca-492d-c9b7-a3f31d90dd36"},"source":["print(class_r)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["                         precision    recall  f1-score   support\n","\n","                enu.cnt       0.99      0.97      0.98       213\n","      enu.discountprice       0.50      0.50      0.50         4\n","                 enu.nm       0.96      0.97      0.97       221\n","                enu.num       0.50      0.50      0.50         4\n","              enu.price       0.96      0.97      0.97       222\n","            enu.sub_cnt       0.88      0.94      0.91        32\n","             enu.sub_nm       0.91      0.96      0.93        45\n","          enu.sub_price       0.77      0.67      0.71        15\n","          enu.unitprice       0.98      0.94      0.96        52\n","         otal.cashprice       0.96      0.97      0.96        66\n","       otal.changeprice       0.98      0.95      0.97        66\n","   otal.creditcardprice       0.78      0.93      0.85        15\n","       otal.emoneyprice       1.00      1.00      1.00         4\n","       otal.menuqty_cnt       0.88      0.88      0.88        26\n","      otal.menutype_cnt       1.00      0.67      0.80         3\n","         otal.total_etc       0.00      0.00      0.00         5\n","       otal.total_price       0.91      0.94      0.93       102\n","ub_total.discount_price       0.62      0.83      0.71         6\n","           ub_total.etc       0.00      0.00      0.00         1\n"," ub_total.service_price       0.92      0.92      0.92        13\n","ub_total.subtotal_price       0.96      0.93      0.94        71\n","     ub_total.tax_price       0.96      1.00      0.98        49\n","\n","              micro avg       0.95      0.95      0.95      1235\n","              macro avg       0.79      0.79      0.79      1235\n","           weighted avg       0.95      0.95      0.95      1235\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9T_AvnJ-nIKx","executionInfo":{"status":"ok","timestamp":1606486549262,"user_tz":-60,"elapsed":53358,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["test_sampler = RandomSampler(test_dataset)\n","test_dataloader = DataLoader(\n","        test_dataset,\n","        sampler=test_sampler,\n","        batch_size=2,\n","        collate_fn=None,\n","    )\n","nb_eval_steps = 0\n","preds_test = None\n","out_label_ids = None\n","model.eval()\n","for step, batch in enumerate(train_dataloader):\n","  with torch.no_grad():\n","    inputs = {\n","        \"input_ids\": batch[0].to(device),\n","        \"attention_mask\": batch[1].to(device),\n","        \"labels\": batch[3].to(device),\n","    }\n","    if model_type in [\"layoutlm\"]:\n","        inputs[\"bbox\"] = batch[4].to(device)\n","    inputs[\"token_type_ids\"] = (\n","        batch[2].to(device) if model_type in [\"bert\", \"layoutlm\"] else None)\n","    # model outputs are always tuple in pytorch-transformers (see doc)\n","    outputs = model(**inputs)\n","    _, logits = outputs[:2]\n","  if preds_test is None:\n","    preds_test = logits.detach().cpu().numpy()\n","    out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n","  else:\n","    preds_test = np.append(preds_test, logits.detach().cpu().numpy(), axis=0)\n","    out_label_ids = np.append(\n","        out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0\n","    )\n","\n","res, report = results_test(preds_test, out_label_ids, labels)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"audIOKGL99ir","executionInfo":{"status":"ok","timestamp":1606486552532,"user_tz":-60,"elapsed":940,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"898fdcac-3d84-4b2a-9552-bc10699792c5"},"source":["res"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'f1': 0.985912865006064,\n"," 'precision': 0.9861888764464353,\n"," 'recall': 0.9856370080208916}"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JeJadGsH-CEI","executionInfo":{"status":"ok","timestamp":1606486555089,"user_tz":-60,"elapsed":515,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"5b694671-f75f-47e3-de91-4bb82fa40955"},"source":["print(report)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["                         precision    recall  f1-score   support\n","\n","                enu.cnt       1.00      1.00      1.00      1887\n","      enu.discountprice       0.84      0.93      0.88        82\n","       enu.itemsubtotal       0.00      0.00      0.00         1\n","                 enu.nm       0.99      0.99      0.99      2060\n","                enu.num       1.00      0.88      0.93        90\n","              enu.price       0.99      0.99      0.99      2058\n","            enu.sub_cnt       0.98      0.98      0.98       140\n","             enu.sub_nm       0.96      0.99      0.97       273\n","          enu.sub_price       0.96      0.94      0.95       121\n","          enu.unitprice       0.99      0.98      0.99       612\n","         otal.cashprice       0.99      0.99      0.99       527\n","       otal.changeprice       0.99      0.98      0.99       505\n","   otal.creditcardprice       0.97      0.97      0.97       119\n","       otal.emoneyprice       0.96      0.96      0.96        50\n","       otal.menuqty_cnt       0.95      0.99      0.97       230\n","      otal.menutype_cnt       0.87      0.79      0.82        42\n","         otal.total_etc       0.88      0.88      0.88        26\n","       otal.total_price       0.98      0.99      0.98       780\n","ub_total.discount_price       0.98      0.95      0.97        65\n","           ub_total.etc       0.97      0.96      0.97        72\n"," ub_total.service_price       1.00      0.99      0.99        91\n","ub_total.subtotal_price       0.98      0.97      0.98       536\n","     ub_total.tax_price       0.98      0.99      0.98       355\n","\n","              micro avg       0.99      0.99      0.99     10722\n","              macro avg       0.92      0.92      0.92     10722\n","           weighted avg       0.99      0.99      0.99     10722\n","\n"],"name":"stdout"}]}]}